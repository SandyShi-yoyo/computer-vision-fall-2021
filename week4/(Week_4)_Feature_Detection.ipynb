{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Week 4) Feature Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPenj5Yxj0mO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCp4KNhvkakN",
        "colab_type": "text"
      },
      "source": [
        "### Read this First\n",
        "\n",
        "#### Remember that `tab` is is useful for autocompletion.\n",
        "\n",
        "#### Remember that `shift + tab` is useful for rapidly obtaining usage + documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsEv_O527qu8",
        "colab_type": "text"
      },
      "source": [
        "###**Corner Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGcOE9_I7ztp",
        "colab_type": "text"
      },
      "source": [
        "**Over the past couple of weeks we've seen how we're able to do certain things with single images, such as binary image processing, and edge detection. This is all good when we want to manipulate a single image, but what happens if we want to find matches between two images? We need features to do so, and corner detection is a very useful tool that can be used to find corners, which is a very useful feature.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFTBoj9KBMIF",
        "colab_type": "text"
      },
      "source": [
        "**In this notebook we'll run through the Harris corner detector to see how we can find corners in the image in order to use as image features.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXOcYQQEByJQ",
        "colab_type": "text"
      },
      "source": [
        "**Let's first load an image to do corner detection with. Notice that we scale the grayscale image so that when we multiply derivatives the values don't explode.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edGODihf7qPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "color_image = cv2.imread('corner_detection.jpg', cv2.IMREAD_COLOR)\n",
        "gray_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY) / 255.0\n",
        "rows, cols = gray_image.shape\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.imshow(gray_image, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8MM8_7rCIRj",
        "colab_type": "text"
      },
      "source": [
        "**In the lecture, we saw that to find corners, a patch containing corners has to have strong edge response in multiple directions. Using scipy's gaussian filter, apply a derivative of gaussian filter with a sigma of 3 to get i_x, the gradient response in the x direction, and i_y, the gradient response in the y direction. Display both results below.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q9K5_yA7qM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.ndimage.filters import gaussian_filter\n",
        "\n",
        "i_x =\n",
        "i_y = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYgViAR4DQxB",
        "colab_type": "text"
      },
      "source": [
        "**Recall that previously for edge detection we then took the gradients in the x and y direction and computed the magnitude. This is nice, but it's not really useful since the magnitude is a scalar number. Corners require us to have strong edges in multiple directions, so condensing the gradient information into a single number causes us to lose the directionality of the response, making us unable to tell if it is a corner.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDvVkuitDsyK",
        "colab_type": "text"
      },
      "source": [
        "**Hence in class we saw that we can find these responses by considering how a patch of an image changes in intensity as we move it around. After some derivation with Taylor series approximation, we see that the change is dependent on the local gradients, which form the H matrix.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17RMC8OfFJG-",
        "colab_type": "text"
      },
      "source": [
        "**First, using i_x and i_y, compute $I^2_x$, $I_xI_y$, and $I_y^2$. Also show that $I_xI_y=I_yI_x$**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjYOpuYSFuAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i_x2 = \n",
        "i_xy = \n",
        "i_y2 = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eATcLuCLF4hg",
        "colab_type": "text"
      },
      "source": [
        "**Now that we have $I^2_x$, $I_xI_y$, and $I^2_y$, can we directly form the H matrix at every pixel based on those values? No! Recall that to find corners, we have to consider a small local area. Hence at each pixel (i, j), we have to sum up the $I^2_x$, $I_xI_y$, and $I^2_y$ values in the neighbouring pixels to get the H matrix for our current pixel.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1BvEUXmHCSV",
        "colab_type": "text"
      },
      "source": [
        "**For every pixel in the image, compute the H matrix based on a neighbourhood of 7x7. That is, for every pixel, compute the sum of $I^2_x$, the sum of $I_xI_y$, and the sum of $I_y^2$ of itself and its neighbours within the 7x7 region centered about that pixel.**\n",
        "\n",
        "**You don't have to explicitly create a matrix for every pixel - just save it in three 2D arrays in the same shape as the image, with the first storing the $I^2_x$ values, the second storing the $I_xI_y$ values, and the third storing the $I^2_y$ values.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06ldKlXPHBGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i_x2_sum = \n",
        "i_xy_sum = \n",
        "i_y2_sum = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITkTbNg2Hip9",
        "colab_type": "text"
      },
      "source": [
        "**Though a square neighbourhood area works, one of the largest issues is that this weighs the contribution of the neighbouring pixels equally. For pixel $(i, j)$, pixels far from $(i, j)$ have the same impact as pixels closer to $(i, j)$, as long as they are all in the neighbourhood. This isn't a great assumption, so we often want to weigh the pixels in the neighbourhood so that the pixels closer to $(i, j)$ count more.**\n",
        "\n",
        "**A gaussian distribution centered about our pixel $(i, j)$ does exactly this!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuvRp4ZNIg_-",
        "colab_type": "text"
      },
      "source": [
        "**For every pixel in the image, compute the H matrix based on a gaussian neighbourhood of sigma=3. That is, for every pixel, compute the sum of $I^2_x$, the sum of $I_xI_y$, and the sum of $I_y^2$ of itself and its neighbours, with the values of each neighbouring pixel weighted by a gaussian distribution with sigma=3.**\n",
        "\n",
        "**(If you used a for loop to do the previous question, you're probably going to have a hard time doing this with the same method - think convolutions!)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqaD56UEI7dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i_x2_sum = \n",
        "i_xy_sum = \n",
        "i_y2_sum = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqpV3cTcJuhZ",
        "colab_type": "text"
      },
      "source": [
        "**Now that we have the contents of the H matrix for every pixel computed, we can then move to the next step - which we saw was computing the eigenvalues of the matrix.**\n",
        "\n",
        "**Using the equation in the slides, write a function that computes the eigenvalues of a 2x2 matrix.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQk2PTvyGp0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_eigenvalues(h11, h12, h21, h22):\n",
        "    \"\"\" Computes the eigenvalues of the H matrix\n",
        "        H = [[h11 h12],\n",
        "             [h21 h22]]\n",
        "        Args: \n",
        "            h11: The value in top left of the matrix\n",
        "            h12: The value in top right of the matrix\n",
        "            h21: The value in bottom left of the matrix\n",
        "            h22: The value in bottom right of the matrix\n",
        "        Returns:\n",
        "            lambda_1: The first eigenvalue of the matrix\n",
        "            lambda_2: The second eigenvalue of the matrix\n",
        "    \"\"\"\n",
        "\n",
        "    # Finish the function\n",
        "\n",
        "    return lambda_1, lambda_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ils_qhB8L9v_",
        "colab_type": "text"
      },
      "source": [
        "**Now that we have a method of computing the eigenvalues of the H matrix at each pixel, we need to find the Harris corner response at each pixel. For every pixel, compute the harris corner response using the H matrix and the eigenvalues. Save those values in h_responses, and plot it**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2JY2bYKMWyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h_responses = np.zeros((rows, cols), dtype=np.float64)\n",
        "k = 0.04\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVBmoAyaQY8Y",
        "colab_type": "text"
      },
      "source": [
        "**We then want the maximal responses, so we should threshold and perform non-maximum suppression. These are implemented for you.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcSjsSt_FImn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.ndimage.filters import maximum_filter\n",
        "\n",
        "threshold = 0.08\n",
        "h_responses = h_responses / np.max(h_responses)\n",
        "h_responses[h_responses < threshold] = 0\n",
        "\n",
        "suppressed = np.copy(h_responses)\n",
        "filtered = maximum_filter(suppressed, (3, 3))\n",
        "maxima = (suppressed == filtered)\n",
        "suppressed[np.logical_not(maxima)] = 0\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(suppressed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWs_VjpJXlxd",
        "colab_type": "text"
      },
      "source": [
        "**Finally, we have points of maximum that correspond to the corners. Using those maxima, plot a small red circle onto the original color_image at those locations. Display the result (Make sure to display in RGB so it looks nice).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNj8_3KnRaQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v3LVD28X7-j",
        "colab_type": "text"
      },
      "source": [
        "**Notice how the the red dots are were the corners end to be, and the red dots that exist in both images tend to be in the same locations - which goes to show that corners are nice features.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we-JkeZLYHsk",
        "colab_type": "text"
      },
      "source": [
        "**Also see that there are a lot of different parameters, such as the $k$ when computing the harris corner response, the size of the gaussian window when computing the H matrix, and also the threshold near the end. Feel free to play around with those and note down the observations that you see.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCkjleXFYT1s",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beV5GSJRYahf",
        "colab_type": "text"
      },
      "source": [
        "###**Blob Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsJBQLiKfG0J",
        "colab_type": "text"
      },
      "source": [
        "**We saw just now that we were able to detect corners in images to serve as features. However, we saw in lecture that even though corner response is invariant with respect to rotation, it is not invariant to scaling. Blob detection on the other hand, is invariant to orientation and size!**\n",
        "\n",
        "**For this portion, I'll walk you through the beginnings of blob detection, but we won't be implementing an entire blob detection algorithm, since there's a few details that are out of the scope for this class.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0x4pmMm7qHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import data\n",
        "from scipy import ndimage\n",
        "\n",
        "color_image = data.hubble_deep_field()[0:500, 0:500]\n",
        "image = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY) / 255.0  \n",
        "plt.imshow(color_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGMRTZW26tBd",
        "colab_type": "text"
      },
      "source": [
        "**We want to be able to detect the blobs (galaxies in the image) using blob detection. We saw that we could do this by convolving the image with a normalized laplacian of gaussian of different sizes. Because this is slow, we saw in lecture that we could approximate this using a difference of gaussians.**\n",
        "\n",
        "**Let's try this out in 1D first. Plot the original_signal shown here below.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2ZkBDQL80R7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_signal = np.zeros(400)\n",
        "original_signal[130:270] = 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CiBxWVG9iYS",
        "colab_type": "text"
      },
      "source": [
        "**Now we want to filter by the laplacian to find the presence of the blob in the original signal. Using ndimage.gaussian_laplace, convolve our original signal with the laplacian with a sigma=3. Plot the result.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JCWsG9g9ixU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP4lJD_i-gHu",
        "colab_type": "text"
      },
      "source": [
        "**Now try convolving with a laplacian of sigma=10, and another with sigma=30, and plot them both separately.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZOuuXkb-k86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VqVWMuX-0eu",
        "colab_type": "text"
      },
      "source": [
        "**We observe the sigma=30 response is more similar to what we are looking for, where there is a single extrema. However, notice the y-axis scale values! What happens as we increase sigma?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLDSwQs2-9p-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP5h7o8w-_vL",
        "colab_type": "text"
      },
      "source": [
        "**Because the larger gaussians produce a great smoothing component (hence decreasing the blob magnitude), we want to normalize this by multiplying the response by $\\sigma^2$. Do this below, by convolving our original signal with a laplacian of size $\\sigma=20$ and multiplying this response by $\\sigma^2$.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyEGXu0h_arW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU8HDkh7_34p",
        "colab_type": "text"
      },
      "source": [
        "**Change the value of sigma to see at which sigma we have the maximal response. Why do we expect it to be this sigma?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_S1ZzvMAAiQ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H03tX7hQABOj",
        "colab_type": "text"
      },
      "source": [
        "**We can also use the difference of gaussians (DoG) as an approximation of normalized laplacian of gaussians (NLoG). Let's show this.** \n",
        "\n",
        "**Convolve the original_signal using a gaussian of sigma=10 and a gaussian of sigma=15. Also convolve the original_signal using a laplacian of size sigma=10**\n",
        "\n",
        "**Plot the difference between the gaussians. On the same graph, plot the laplacian response, scaled by multiplying by 40.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_ZpY2dCAsFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ3Ua21OCH7B",
        "colab_type": "text"
      },
      "source": [
        "**Is this what you expected?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "capyI5gLCJc1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFi4Po7cCM5V",
        "colab_type": "text"
      },
      "source": [
        "**Now, let's try and do the same thing in 2D**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFRJ_0RQCUvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "color_image = data.hubble_deep_field()[0:500, 0:500]\n",
        "image = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY) / 255.0  \n",
        "plt.imshow(color_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAgYxb2uCZJY",
        "colab_type": "text"
      },
      "source": [
        "**We have the image, and we have a set range of $k$'s and $s$'s. We first want to compute the difference of gaussians given our $k$ and $s$ parameters. Do this by setting glo to be the response after filtering with a gaussian of $\\sigma=k^i$, and setting ghi as the response after filtering with a gaussian of $\\sigma=k^{i+1}$. Then, save the difference between glo and ghi in dogs.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QykBbNd8DDkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finds the dimensions of the image\n",
        "rows, cols = image.shape\n",
        "\n",
        "# Hyperparameters\n",
        "k = 2 ** (0.2)      # Difference between the sigmas of the different gaussian levels\n",
        "s = 28              # Number of levels\n",
        "\n",
        "# Create containers for the difference of gaussians (dogs) and the gradient of those (gods)\n",
        "dogs = np.zeros((rows, cols, s))\n",
        "sigmas = np.zeros((1, s))\n",
        "\n",
        "# Loops through every level to create a gaussian filtered image at each level\n",
        "for i in range(s):\n",
        "\n",
        "    # Performs gaussian filtering\n",
        "    glo = \n",
        "    ghi = \n",
        "\n",
        "    # Saves the difference and the corresponding sigma simulateneously\n",
        "    dogs[:, :, i] = \n",
        "    sigmas[0, i] = k ** i\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynuye8eUDIe7",
        "colab_type": "text"
      },
      "source": [
        "**Once we have a response for a wide range of DoGs, we then have to find the local extrema in order to find points of interest (where there is a good response to the NLoG, which suggests a blob of that size is in the image.**\n",
        "\n",
        "**Compare each point in dogs with its 3x3x3 grid, and save the $(i, j, k)$ coordinates as a tuple into pois if it is the local minimum or maximum.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnnDsxy9D4KW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finds the initial points of interest by taking local maxima and minima\n",
        "# Compares each point with its 3x3x3 grid and saves it if it the local maximum or minimum\n",
        "pois = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuIe7jFKEFaz",
        "colab_type": "text"
      },
      "source": [
        "**We can then plot some circles on the original image to see what our blob response yields.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsHajPEBEKba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testim = color_image.copy()\n",
        "for i in range(len(pois)):\n",
        "  cv2.circle(testim, (pois[i][1], pois[i][0]), radius=int(sigmas[0, pois[i][2]]), color=(0, 255, 0), thickness=1)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(testim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q7xHh7XExBb",
        "colab_type": "text"
      },
      "source": [
        "**Though we see that a lot of the galaxies have green circles bounding them that seems like about the right size, there's a lot of responses. We need to do some post-processing to remove the weaker points in the image.**\n",
        "\n",
        "**Below is some code I wrote a while ago to do some filtering - I'm don't recall what it really does anymore or why I did this, and it works okay. Just run it and hopefully it works.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnO_DcS-7qFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We then have to remove weak points\n",
        "refined_pois = []\n",
        "for i in range(len(pois)):\n",
        "    y = pois[i][0]\n",
        "    x = pois[i][1]\n",
        "    sig = pois[i][2]\n",
        "\n",
        "    # We find the derivatives and double derivatives in both directions and across sigma\n",
        "    dx = dogs[y, x + 1, sig] - dogs[y, x - 1, sig]\n",
        "    dy = dogs[y + 1, x, sig] - dogs[y - 1, x, sig]\n",
        "    dsig = dogs[y, x, sig + 1] - dogs[y, x, sig - 1]\n",
        "    dx2 = (dogs[y, x + 2, sig] - dogs[y, x, sig]) - (dogs[y, x, sig] - dogs[y, x - 2, sig])\n",
        "    dy2 = (dogs[y + 2, x, sig] - dogs[y, x, sig]) - (dogs[y, x, sig] - dogs[y - 2, x, sig])\n",
        "    dsig2 = (dogs[y, x, sig + 2] - dogs[y, x, sig]) - (dogs[y, x, sig] - dogs[y, x, sig - 2])\n",
        "\n",
        "    # We estimate the feature location coordinate using a formula in the writeup\n",
        "    xest_x = - (1.0 / dx2) * dx\n",
        "    xest_y = - (1.0 / dy2) * dy\n",
        "    xest_sig = - (1.0 / dsig2) * dsig\n",
        "\n",
        "    # If the feature location is too far, we ignore this point. If not:\n",
        "    if abs(xest_x) < 0.5 and abs(xest_y) < 0.5 and abs(xest_sig) < 0.5:\n",
        "        new_x = x + xest_x\n",
        "        new_y = y + xest_y\n",
        "        new_sig = sig + xest_sig\n",
        "\n",
        "        # We find the location of the local extrema\n",
        "        bd_x = dogs[y, x, sig] + 0.5 * dx * xest_x\n",
        "        bd_y = dogs[y, x, sig] + 0.5 * dy * xest_y\n",
        "        bd_sig = dogs[y, x, sig] + 0.5 * dsig * xest_sig\n",
        "\n",
        "        # If the value is too low, it is unstable or low contrast so ignore. If not, we add it into the list\n",
        "        if np.sqrt(bd_x**2 + bd_y**2 + bd_sig**2) >= 0.025:\n",
        "            refined_pois.append((int(round(new_y)), int(round(new_x)), int(round(new_sig))))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G89ed0KFtBR",
        "colab_type": "text"
      },
      "source": [
        "**We then plot the refined points again.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsFJexNj7qCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_im = color_image.copy()\n",
        "for i in range(len(refined_pois)):\n",
        "  cv2.circle(display_im, (refined_pois[i][1], refined_pois[i][0]), radius=int(sigmas[0, refined_pois[i][2]]), color=(0, 255, 0), thickness=1)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(display_im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5EIUmqoFxki",
        "colab_type": "text"
      },
      "source": [
        "**We should see that the majority of the green circles have disappeared, and not we only have circles around some of the larger galaxies, and it seems to be capturing them well (assuming you did what I did). You'll see some extra circles near the edges of the galaxies, which we don't want, since these features aren't interesting (they are formed because of the black blobs).**\n",
        "\n",
        "**Hence some more processing has to be done. But we won't do that here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kss-tFq1GHz6",
        "colab_type": "text"
      },
      "source": [
        "**Instead, let's use some library functions like we always do.**\n",
        "\n",
        "**Run the code below that I found in the scikit-image docs that shows a couple of ways we can do blob detection.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt5087js7p3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import sqrt\n",
        "from skimage import data\n",
        "from skimage.feature import blob_dog, blob_log, blob_doh\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "image = data.hubble_deep_field()[0:500, 0:500]\n",
        "image_gray = rgb2gray(image)\n",
        "\n",
        "blobs_log = blob_log(image_gray, max_sigma=30, num_sigma=10, threshold=.1)\n",
        "\n",
        "# Compute radii in the 3rd column.\n",
        "blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n",
        "\n",
        "blobs_dog = blob_dog(image_gray, max_sigma=30, threshold=.1)\n",
        "blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
        "\n",
        "blobs_doh = blob_doh(image_gray, max_sigma=30, threshold=.01)\n",
        "\n",
        "blobs_list = [blobs_log, blobs_dog, blobs_doh]\n",
        "colors = ['yellow', 'lime', 'red']\n",
        "titles = ['Laplacian of Gaussian', 'Difference of Gaussian',\n",
        "          'Determinant of Hessian']\n",
        "sequence = zip(blobs_list, colors, titles)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True)\n",
        "ax = axes.ravel()\n",
        "\n",
        "for idx, (blobs, color, title) in enumerate(sequence):\n",
        "    ax[idx].set_title(title)\n",
        "    ax[idx].imshow(image)\n",
        "    for blob in blobs:\n",
        "        y, x, r = blob\n",
        "        c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n",
        "        ax[idx].add_patch(c)\n",
        "    ax[idx].set_axis_off()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}