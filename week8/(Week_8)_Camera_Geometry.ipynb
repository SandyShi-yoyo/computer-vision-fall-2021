{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Week 8) Camera Geometry.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TgFDOQD0mxL2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZBLjVlNlgox"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy import signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgFDOQD0mxL2"
      },
      "source": [
        "### Read this First\n",
        "\n",
        "#### Remember that `tab` is is useful for autocompletion.\n",
        "\n",
        "#### Remember that `shift + tab` is useful for rapidly obtaining usage + documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgqGhZUDmz5y"
      },
      "source": [
        "###**3D Camera Geometry**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnsOTCvam3dI"
      },
      "source": [
        "**In class we covered material for single and multi-camera systems. This notebook will help ground some of these geometric concepts.**\n",
        "\n",
        "**First, we'll define some of the components helpful for for camera geometry**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM5v1tZzq_7l"
      },
      "source": [
        "def rotatex(t) :\n",
        "  \"\"\" Creates a 3D rotation matrix representing a rotation about the x-axis by t radians \"\"\"\n",
        "  return np.array([[1,0,0],[0,np.cos(t),-np.sin(t)],[0,np.sin(t),np.cos(t)]])\n",
        "\n",
        "def rotatey(t) :\n",
        "  \"\"\" Creates a 3D rotation matrix representing a rotation about the y-axis by t radians \"\"\"\n",
        "  return np.array([[np.cos(t),0,np.sin(t)],[0,1,0],[-np.sin(t),0,np.cos(t)]])\n",
        "\n",
        "def rotatez(t) :\n",
        "  \"\"\" Creates a 3D rotation matrix representing a rotation about the z-axis by t radians \"\"\"\n",
        "  return [[np.cos(t),-np.sin(t),0],[np.sin(t),np.cos(t),0],[0,0,1]]\n",
        "\n",
        "def rotate2D(t) :\n",
        "  \"\"\" Creates a 2D rotation matrix representing a rotation by t radians \"\"\"\n",
        "  return [[np.cos(t),-np.sin(t)],[np.sin(t),np.cos(t)]]\n",
        "\n",
        "def trans(x,y,z) :\n",
        "  \"\"\" Creates a 3D translation vector of shape 3x1 \"\"\"\n",
        "  return np.array([[x,y,z]]).T\n",
        "\n",
        "def pointh(x,y,z) :\n",
        "  \"\"\" Creates a 3D point in homogeneous coordinates \"\"\"\n",
        "  return np.array([[x,y,z,1]].T)\n",
        "\n",
        "def htrans(R,t) :\n",
        "  \"\"\" Creates a 3D homogeneous transformation matrix \"\"\"\n",
        "  return np.concatenate((np.concatenate((R,t),axis=1),np.array([[0,0,0,1]])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BgcMwI-jrGj"
      },
      "source": [
        "**Now, we'll define some components for camera internal geometry**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "difUAAAk6Avj"
      },
      "source": [
        "def Kmatrix(sx,sy,ox,oy) :\n",
        "  \"\"\" Creates the matrix K that represents the calibration matrix \"\"\"\n",
        "  return np.array([[sx,0,ox],[0,sy,oy],[0,0,1]])\n",
        "\n",
        "def Mmatrix(K) :\n",
        "  \"\"\" Creates the matrix M that represents the intrinsic matrix \"\"\"\n",
        "  return np.concatenate((K, np.array([[0,0,0]]).T),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_03oZyujrGm"
      },
      "source": [
        "**Now, write a function that, given a intrinsic matrix M and a extrinsic matrix H, computes the projection matrix P.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgW6r4yRjrGn"
      },
      "source": [
        "def Pmatrix(M, H):\n",
        "  \"\"\" Creates a 3x4 projection matrix P that relates world coordinates to pixel coordinates\n",
        "      Args:\n",
        "        M: 3x4 matrix representing the intrinsic parameters of the camera\n",
        "        H: 4x4 matrix representing the extrinsic parameters of the camera\n",
        "      Return:\n",
        "        P: 3x4 matrix relating world coordinates to pixel coordinates\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "  return P"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcPPA9g2pO3x"
      },
      "source": [
        "**Now, let's make some real world points to project.  Since this is a camera, we'll make the z axis larger than x and y**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLV-RSixjrGs"
      },
      "source": [
        "# Make 20 random 3D points stacked horizontally \n",
        "pts = np.concatenate((np.random.random([3,20]),np.ones([1,20])),axis=0)\n",
        "pts[0:2,:] = (pts[0:2,:] - 0.5) * 100\n",
        "pts[2,:] = (pts[2,:] - 0.5) * 100 + 1000\n",
        "\n",
        "# Plot these points\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "plt.scatter(pts[0],pts[1],zs=pts[2],s=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4jHqcJKtVkb"
      },
      "source": [
        "**Create an K matrix with parameters $s_x=s_y=1000$, $o_x=52.2$, $o_y=55.3$. Create a H matrix with identity rotation and a translation $(x, y, z)=(42, 33, 1000)$. Then, using those, create the P matrix and print the resulting matrix.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr-xvJ7buoOT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwu3dh1N0sEA"
      },
      "source": [
        "**Transform our real world points pts using this projection matrix and store the resulting pixel coordinates into pix_pts. Remember that the results are in homogeneous coordinates so when we plot it we have to ensure that $w=1$ for hoomogeneous coordinate $(u, v, w)$**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kUEbvxavTQD"
      },
      "source": [
        "pix_pts = np.zeros((3, 20))\n",
        "\n",
        "\n",
        "# Plot these points\n",
        "fig = plt.figure()\n",
        "plt.scatter(pix_pts[0], pix_pts[1], s=5)\n",
        "plt.gca().invert_yaxis()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LldzxXYp1A0d"
      },
      "source": [
        "**Why did I invert the y axis here?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRnX-02R1Cw7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5N9JsC_1DIV"
      },
      "source": [
        "**Now we want to compare this with the plot of pts above to see how similar our camera view with the real world. Plot pts as before using scatter, but now adjust viewpoint of the plot to have elevation as $-90$ and azimuth as $-90$.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRKx6lCHwPRL"
      },
      "source": [
        "# Plot pts again but with a different viewpoint\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTeEyCZ51lrS"
      },
      "source": [
        "**Which directions are the x, y, and z axes? (i.e. which is the vertical/horizontal/in or out of plane axis? Which direction is the positive direction for each?)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoipQBW01ykt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM2T0uuh1y3N"
      },
      "source": [
        "**Do your camera points look the same as the real world points? (They should)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbvXpZPV2SKz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEj5UVwO14vX"
      },
      "source": [
        "**Now, change the parameters such that $o_x=0$, recompute the projection matrix, reproject the real world points to the pixel coordinates and plot it as before.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTmj1soR2Ryf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyfA3rPk3AA0"
      },
      "source": [
        "**What changed between this and the previous plot you made? What does the parameter $o_x$ represent?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvea9MWd3NMm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOPBS_3-3OS-"
      },
      "source": [
        "**Now change $s_y=400$ and do the same thing. Keep $o_x=0$ so you can compare without scrolling too far.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWh4IVzJ3Nhi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pCR6k0y3sFZ"
      },
      "source": [
        "**What changed between this and the previous plot you made? What does the parameter $s_y$ represent?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nrn9sj63twD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEHIKzrR3uB2"
      },
      "source": [
        "**Now let's try and recover the projection matrix. We've already covered this in the Week 6 Python Notebook, so it should be relatively straightforward. Using the real world coordinates pts and the pixel coordinates obtained when we set $s_y=400$ and $o_x=0$ above, create the $A$ matrix in $Ap=0$ that was covered in class to solve for the projection matrix.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLL0NnJS86w4"
      },
      "source": [
        "A = np.zeros((2 * 20, 12))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkcL-NWr9jQ6"
      },
      "source": [
        "**Compute the projection matrix P by solving for $Ap=0$, and print it. Compare it with the projection matrix computed above to confirm that they are identical.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxnJFVIZ2s0K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyWt2Cz290Xb"
      },
      "source": [
        "**Recover the K and R matrices, and then the translation vector t using RQ factorization, and print them to make sure they are consistent with the parameters that you provided to create the projection matrix.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnxnKxgu2s3i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDvLpXd5-y7j"
      },
      "source": [
        "**Now pick your own parameters for the intrinsic and extrinsic matrices, project pts, and then recover the projection matrix P. Double check that you're able to recover the matrix.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAr5xBFi2suZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYmdlls5_AcF"
      },
      "source": [
        "###**Uncalibrated stereo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMn8ygXotcwZ"
      },
      "source": [
        "**Now that we're more confident with single camera geometry, let's try relate the geometries and the viewpoints of two cameras. The goal of this is to be able to find a relationship between the location of an object in one camera view and the location of the object in the other camera view.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nCvYbKnti5r"
      },
      "source": [
        "**Here, let's create 20 random points again** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtHva4McD_i1"
      },
      "source": [
        "# Make 20 random 3D points stacked horizontally \n",
        "npoints = 20\n",
        "pts = np.concatenate((np.random.random([3, npoints]),np.ones([1, npoints])),axis=0)\n",
        "pts[0:2,:] = (pts[0:2,:] - 0.5) * 100\n",
        "pts[2,:] = (pts[2,:] - 0.5) * 100 + 1000\n",
        "colors = plt.cm.rainbow(np.linspace(0, 1, npoints))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp-0lzB3uEK6"
      },
      "source": [
        "**We also plot these points, is a couple of different views that will make more sense that the default view.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCVSJjSDJEwx"
      },
      "source": [
        "# Plot these points\n",
        "fig = plt.figure(figsize=(48, 8))\n",
        "ax = fig.add_subplot(131, projection='3d')\n",
        "plt.scatter(pts[0],pts[1],zs=pts[2],s=21, c=colors)\n",
        "ax.view_init(elev=-70, azim=-90)\n",
        "\n",
        "ax2 = fig.add_subplot(132, projection='3d')\n",
        "plt.scatter(pts[0],pts[1],zs=pts[2],s=21, c=colors)\n",
        "ax2.view_init(elev=-30, azim=-90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3DB6EtMuLi8"
      },
      "source": [
        "**Now we want to simulate two cameras. For camera 1, create a projection matrix with parameters $s_x=s_y=1000$, $o_x=35$, $o_y=55.3$, with a y-axis rotation by -0.3 radians, and a translation vector of $[280, 33, 1000]$.** \n",
        "\n",
        "**Project the real world pts above into the view of this camera, and plot these pixel coordinates with the same colours as above corresponding to each point (set c=colors) and remember to invert the y-axis.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9396tWlYFb_N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlIe1WaKuzzc"
      },
      "source": [
        "**Now simulate camera 2, by creating a projection matrix with parameters $s_x=s_y=1000$, $o_x=35$, $o_y=55.3$, with a y-axis rotation by 0.3 radians, and a translation vector of $[390, 33, 1000]$.** \n",
        "\n",
        "**Project the real world pts above into the view of this camera, and plot these pixel coordinates with the same colours as above corresponding to each point (set c=colors) and remember to invert the y-axis.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecQkIIQLF0fT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_jqAuRRu6wI"
      },
      "source": [
        "**Which camera is the camera on the left? How can you tell?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abf7HInuu-Cq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmwrp2dou-t1"
      },
      "source": [
        "**Now we have the pixel coordiantes in both images and we know which pairs of points correspond to each other, we can solve for the fundamental matrix, which relates pixel coordinates from one image to another.**\n",
        "\n",
        "**Below, fill in the matrix A that you find in slide 46**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeoBPfYvKOa9"
      },
      "source": [
        "A = np.zeros((npoints, 9))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THnrTDH6vUV8"
      },
      "source": [
        "**Solve for the fundamental matrix given that $Af=0$, and print out the fundamental matrix F. For reference please see slide 62.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owq2lMP6NLzl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NLTaPJdvs1m"
      },
      "source": [
        "**Try and recover the essential matrix. We can do this because you already know the calibration matrices $K_r$ and $K_l$. Display the result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzpfEbMGWNse"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO_Vno6TwHdc"
      },
      "source": [
        "**Given the essential matrix, we can also recover the rotation between the two cameras. Compute $R$, the rotation between the two cameras, using the essential matrix $E$. Display it, and then using rotatey() display the actual rotation between the two cameras (check the extrinsic matrices of the cameras to determine the true rotation between them).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iso_a7XhWpgf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAPnn8piwh5e"
      },
      "source": [
        "**Are they the same? They should be.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TdPRv1JwkVt"
      },
      "source": [
        "**Now try and recover the translation, and display the result.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV3Wt8u_W8Xd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEKPSXP1wm_3"
      },
      "source": [
        "**Chances are, this will be different from the true translation between the cameras. Why is this so?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppq13DISwtxt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHR3u8TVwuRi"
      },
      "source": [
        "**Now let's try and plot the epipolar lines. Write a function that given the fundamental matrix and an image pixel coordinate in either the left or the right image, returns the coefficients of the epipolar line in the other image.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyGAMsKE0pCV"
      },
      "source": [
        "def findEpipolar(F, pix_l=None, pix_r=None):\n",
        "  \"\"\" Computes the epipolar line coefficients given the fundamental matrix F and either\n",
        "      the pixel coordinates in the left image (pix_l) or the pixel coordinates in the \n",
        "      right image (pix_r)\n",
        "      Args:\n",
        "        F: Fundamenal matrix 3x3 that relates pixels in one image to another\n",
        "        pix_l: Pixel coordinate in the left image (shape [3, 1])\n",
        "        pix_r: Pixel coordinate in the right image(shape [1, 3])\n",
        "      Return:\n",
        "        line_coeff: The coefficients of the epipolar line in the other image\n",
        "                    If the equation is au + bv + c = 0, the line_coeff = [a, b, c]\n",
        "  \"\"\"\n",
        "\n",
        "  # If the right pixel coordinate is provided, we want to find the coefficients of\n",
        "  # the line in the left image\n",
        "  if pix_l is None:\n",
        "\n",
        "\n",
        "  # If the left pixel coordinate is provided, we want to find the coefficients of \n",
        "  # the line in the right image\n",
        "  elif pix_r is None:\n",
        "\n",
        "\n",
        "  else:\n",
        "    line_coeff = None\n",
        "\n",
        "  return line_coeff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5QdbDHT5H7j"
      },
      "source": [
        "**Now complete the function below, that given the coefficient of the line and either the $x$ or the $y$ coordinate, finds the other one.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVRqfmVD5gVl"
      },
      "source": [
        "def findOther(line_coeff, u=None, v=None):\n",
        "  \"\"\" Given the coefficients of au + bv + c = 0 in the form [a, b, c], compute either\n",
        "      u if v is given, or v if u is given.\n",
        "      Args:\n",
        "        line_coeff: [a, b, c] vector of the coefficients of the equation above\n",
        "        u: The x coordinate of the pixel\n",
        "        v: The y coordinate of the pixel\n",
        "      Return:\n",
        "        The other pixel coordinate, None if nothing else is provided\n",
        "  \"\"\"\n",
        "\n",
        "  if u is None:\n",
        "\n",
        "\n",
        "  elif v is None:\n",
        "\n",
        "\n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o_RT0G3-X6L"
      },
      "source": [
        "**Now, using the two functions above, plot the epipolar lines corresponding to the points from the right image onto the left image. Plot the points in the left image in the same plot. Make sure that the colours match, and each point in the left image should have an epipolar line that passes through them.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HUhCfJ-y1_a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "368RhFpM_Clo"
      },
      "source": [
        "**Now do the same thing, plotting the epipolar lines corresponding to left image points onto the right image.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCXuCpLI-wpU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izm_huEy_Mgz"
      },
      "source": [
        "**Now, change the extrinsics of the right camera to include another rotation in either x or z in addition to the y rotation, find the geometry between the left camera and this new right camera, and plot the epipolar lines.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGGtogVBzZYg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}